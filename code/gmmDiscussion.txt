Test M with maxIter = 20 and Speakers = 32

M: 1 	 Accuracy:  0.9688
M: 2 	 Accuracy:  1.0000
M: 3 	 Accuracy:  1.0000
M: 5 	 Accuracy:  1.0000
M: 7 	 Accuracy:  1.0000
M: 8 	 Accuracy:  1.0000
M: 10 	 Accuracy:  1.0000
M: 12 	 Accuracy:  1.0000
M: 18 	 Accuracy:  1.0000
M: 25 	 Accuracy:  1.0000

Discussion:
Based on the above gained accuracies, we can see that the classification accuracy may decrease
if M decreases, where M is the number of the Gaussian models in the mixture. This makes sense since the smaller
number of the Gaussion models sometimes would not be able to fit the data properly and correctly.
Therefore, the trained mixture Gaussion model for each speaker would not be able to generate an accurate prediction for
each test utterance since the characteristics of the training data for the speaker are not well-represented.
Hence, it is not surprised that the classification accuracy would decrease in this case. It should be noted that
decreasing M only had a minimal effect on accuracy.

These results suggest that each speaker's latent distribution of utterances can be approximated quite well with
only a uni-modal distribution, and that each of these uni-modal distributions are quite distinct to each other (they are
different enough to produce substantially different log-likelihoods when run against data drawn from another speaker).

------------------------------------------------------------------------------------------------------------------------

Let's look at examining the maxIter this time:

Test maxIter with M = 8 and Speakers = 32

maxIter: 0 	 Accuracy:  0.9688
maxIter: 5 	 Accuracy:  1.0000
maxIter: 10  Accuracy:  1.0000
maxIter: 15  Accuracy:  1.0000
maxIter: 20  Accuracy:  1.0000
maxIter: 25  Accuracy:  1.0000
maxIter: 30  Accuracy:  1.0000

Discussion:
The accuracy of the GMM classifier is proportional to the number of training iterations.
The classifier quickly reaches the maxima accuracy between the 0-th and 5-th training iteration. This suggests that the
model converges very fast to a minima.
These results suggest a similar phenomenon as the previous experiment.

------------------------------------------------------------------------------------------------------------------------
Let's look at examining the number of speakers this time:


Test Speakers with M = 8 and maxIter = 20

Total Speakers: 1 	 Accuracy:  1.0000
Total Speakers: 5 	 Accuracy:  1.0000
Total Speakers: 8 	 Accuracy:  1.0000
Total Speakers: 15 	 Accuracy:  1.0000
Total Speakers: 20 	 Accuracy:  1.0000
Total Speakers: 25 	 Accuracy:  1.0000
Total Speakers: 32 	 Accuracy:  1.0000

Discussion:
If we only change the number of speakers for both training and testing, there is no effect on the accuracy of the model.
This is with the assumption that there is no unknown speakers.

------------------------------------------------------------------------------------------------------------------------
Lets change the number of known training speakers this time:

Test Speakers with M = 8 and maxIter = 20 and totalSpeakers = 32


Known Training Speakers: 4 	    Accuracy:  0.125
Known Training Speakers: 8 	    Accuracy:  0.25
Known Training Speakers: 16 	Accuracy:  0.5
Known Training Speakers: 24 	Accuracy:  0.75
Known Training Speakers: 32 	Accuracy:  1.0000

As the number of unknown speakers increases (the known speakers decreases), the classification accuracy decreases by a
noticeable amount. This makes sense since the model trained only contains the information of each of the known speakers.
Therefore, it would assign a "known speaker name" to an unknown speaker during the classification process. Thus, the
classification accuracy would not be good.
It should be noted that the accuracy scores are equal to (S / 32).

------------------------------------------------------------------------------------------------------------------------
Additional Questions

Question 1: How might you improve the classification accuracy of the Gaussian mixtures, without adding more
training data?

Answer 1:
I will increase the number of maxIter so that the model can learn more information from the trainng data,
although I need to be careful about the overfitting issue since, knowing the training set in a very detailed way may
cause the model to not generalize well for unseen data.

Another option is to increase the number of Gaussian mixture
models. M should be tuned such that it equals the number of clusters in the latent distribution. This will ensure that
the latent distribution can be approximated accurately while minimizing the chances of over-fitting. However, since the
properties of the latent distribution are unknown, trial and error must be used to find ideal M.

I would also try different parameter initializations. It's possible for the EM algorithm to get stuck in a local maxima.
and in this way, I can make sure that the chosen paramteres are the optimal ones.
                                 ----------------------------------------
Question 2: When would your classifier decide that a given test utterance comes from none of the trained speaker
models, and how would your classifier come to this decision?

Answer 2:

If all of the GMM models produce likelihoods very low to zero in other words log-likelihoods of -infinity, it means that
it is impossible that the speaker tested is one of the trained speakers. This situation would occur only when the bm
values are all zeros since each likelihood is computed by the sum of the weighted bws.
Perhaps a threshold-based algorithm could approximate the theoretical algorithm of having all GMM's output 0 likelihood
(-infinity log-likelihood). If the log-likelihood produced by the test data is substantially below this threshold, we
may consider the test-data to be "unseen".
                                 ----------------------------------------
Question 3: Can you think of some alternative methods for doing speaker identification that don't use Gaussian
mixtures?

Answer 3:
K nearest neighbours (KNN) and convolutional neural networks (CNN) could be some alternatives. A recent concept is to
use d-vectors which is the output of a neural network model that specifies a speaker with a d-dimensional vector. For
testing if an utterence is similar to a speaker we can then find the similarity scores between the two d-vector embeddings
and if it is over a certain threshold we could say that it comes from the same speaker.
Another alternative is K-means: Running K-means on the utterance data to find the (approximate) k-cluster centers for k-many speakers. For a
new utterance, finding the closest cluster center which represents the speaker.